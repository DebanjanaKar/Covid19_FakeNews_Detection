{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "torch.manual_seed(1525)\n",
    "np.random.seed(1525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading english data\n",
    "import pickle as pkl\n",
    "with open('./resources/covid_en_tweet.pickle', 'rb') as pkl_in:\n",
    "    tweets_en = pkl.load(pkl_in)\n",
    "#loading bengali data\n",
    "with open('./resources/covid_bn_tweet.pickle', 'rb') as pkl_in:\n",
    "    tweets_bn = pkl.load(pkl_in)\n",
    "#loading hindi data\n",
    "with open('./resources/covid_hi_tweet.pickle', 'rb') as pkl_in:\n",
    "    tweets_hi = pkl.load(pkl_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train - test split\n",
    "def split(df):\n",
    "    df_copy = df.copy()\n",
    "    train_set = df_copy.sample(frac=0.80, random_state=0)\n",
    "    print(len(train_set), train_set.head())\n",
    "    test_set_split = df_copy.drop(train_set.index)\n",
    "    #print('-------', len(train_set.index), len(df_copy), len(df_copy) - len(train_set.index), len(test_set))\n",
    "    '''eval_set = test_set_split.sample(frac=0.50, random_state=0)\n",
    "    print(len(eval_set), eval_set.head())\n",
    "    test_set_split = test_set_split.drop(eval_set.index)\n",
    "    print(len(test_set_split), test_set_split.head())'''\n",
    "    return train_set, test_set_split\n",
    "    #, eval_set,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#simple text based classification\n",
    "#very useful library : https://towardsdatascience.com/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3\n",
    "def fake_classify(train_set, test_set):\n",
    "\n",
    "    # Create a TransformerModel\n",
    "\n",
    "\n",
    "    model = ClassificationModel('bert', 'bert-base-multilingual-uncased', args={ 'num_train_epochs': 3, 'overwrite_output_dir': True, 'manual_seed' : 1525}, use_cuda = False)\n",
    "\n",
    "    # Train the model\n",
    "\n",
    "    model.train_model(train_set)\n",
    "\n",
    "    # Evaluate the model\n",
    "\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(test_set, f1=sklearn.metrics.f1_score, acc=sklearn.metrics.accuracy_score)\n",
    "    \n",
    "    \n",
    "    return model, result, model_outputs, wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(result):\n",
    "    prec = result['tp']/(result['tp'] + result['fp'])\n",
    "    rec = result['tp']/(result['tp'] + result['fn'])\n",
    "    fscore = (2*prec*rec)/(prec + rec)\n",
    "    print('Raw result = ', result)\n",
    "    print('Precision = ', prec )\n",
    "    print('Recall = ', rec)\n",
    "    print('F-Score = ', fscore) \n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_en = './resources/en_model'\n",
    "path_bn = './resources/bn_model'\n",
    "path_hi = './resources/hi_model'\n",
    "path_multi = './resources/multi_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del tweets_en['text_info']\n",
    "df_en = pd.DataFrame(tweets_en)\n",
    "print(df_en.head())\n",
    "#train_set_en, eval_set_en, test_set_en = split(df_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classification on bengali tweets\n",
    "del tweets_bn['text_info']\n",
    "df_bn = pd.DataFrame(tweets_bn)\n",
    "print(df_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classification on hindi tweets\n",
    "del tweets_hi['text_info']\n",
    "df_hi = pd.DataFrame(tweets_hi)\n",
    "print(df_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./resources/covid_bn_tweet_test.pickle', 'rb') as pkl_in:\n",
    "    tweets_bn_test = pkl.load(pkl_in)\n",
    "del tweets_bn_test['text_info']\n",
    "df_bn_test = pd.DataFrame(tweets_bn_test)\n",
    "df_bn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilingual model\n",
    "frames = [df_en, df_bn, df_hi, df_bn_test]\n",
    "df_merged = pd.concat(frames)\n",
    "df_merged.index = range(len(df_merged))   #change indices\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#multilingual results\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "\n",
    "best_result = 0\n",
    "kf = KFold(n_splits=5)\n",
    "model_outputs_multi = {}\n",
    "count = 1\n",
    "for train, test in kf.split(df_merged):\n",
    "    print('--------------------------', count, '------------------------------')\n",
    "    #print(\"%s %s\" % (train, test))\n",
    "    df_train_multi = df_merged.copy()\n",
    "    df_test_multi = df_merged.copy()\n",
    "    df_train_multi = df_train_multi.drop(test)\n",
    "    df_test_multi = df_test_multi.drop(train)\n",
    "    print(len(df_train_multi), len(df_test_multi))\n",
    "    \n",
    "    model_multi, result_multi, model_outputs_multi, wrong_predictions_multi = fake_classify(df_train_multi, df_test_multi)\n",
    "    \n",
    "    fscr = results(result_multi)\n",
    "    if fscr > best_result:\n",
    "        best_result = fscr\n",
    "        torch.save(model_multi, path_multi)\n",
    "    \n",
    "    model_outputs_multi[count] = {}\n",
    "    model_outputs_multi[count]['indices'] = test\n",
    "    model_outputs_multi[count]['outputs'] = model_outputs_multi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#storing model outputs of mono and multilingual models\n",
    "with open('./resources/multi_raw_outputs.pickle', 'wb') as pkl_out:\n",
    "    pkl.dump(model_outputs_multi, pkl_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    url = r'http\\S+'\n",
    "    tweet = re.sub(url, 'URL', tweet, flags=re.MULTILINE)\n",
    "    emoji = re.compile(\"[\"         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   u\"\\U0001f926-\\U0001f937\"\n",
    "                                   u\"\\U00010000-\\U0010ffff\"\n",
    "                                   u\"\\u2640-\\u2642\"\n",
    "                                   u\"\\u2600-\\u2B55\"\n",
    "                                   u\"\\u200d\"\n",
    "                                   u\"\\u23cf\"\n",
    "                                   u\"\\u23e9\"\n",
    "                                   u\"\\u231a\"\n",
    "                                   u\"\\ufe0f\"  # dingbats\n",
    "                                   u\"\\u3030\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "    tweet =  emoji.sub(r'', tweet)\n",
    "    tweet = ' '.join([word[1:] if word[0] == '#' else word for word in tweet.split()])\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting predictions on real tweets\n",
    "def predict(path, sent):\n",
    "    model = torch.load(path)\n",
    "    sent = preprocess(sent)\n",
    "    p, ro = model.predict([sent])\n",
    "    c1 = np.exp(ro[0][0])/sum([np.exp(val) for val in ro[0]])\n",
    "    c2 = np.exp(ro[0][1])/sum([np.exp(val) for val in ro[0]])\n",
    "    result = 'This tweet has a verifiable claim.' if p[0] == 1 else 'This tweet does not have a verifiable claim.'\n",
    "    cscore = c2*100 if p[0] == 1 else c1*100\n",
    "    print(sent, ' : ', result)\n",
    "    print('The model says this with a',round(cscore, 2), '% confidence score.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict english tweets\n",
    "sent = input()\n",
    "predict(path_en, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict english tweets\n",
    "sent = input()\n",
    "predict(path_en, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict bengali tweets\n",
    "sent = input()\n",
    "predict(path_bn, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict hindi tweets #example from BBC News Hindi\n",
    "sent = input()\n",
    "predict(path_hi, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict multilingual tweets #example from DW Bangla account\n",
    "sent = input()\n",
    "predict(path_multi, sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covidfake",
   "language": "python",
   "name": "covidfake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
